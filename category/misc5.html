<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
        <title>Open Science Collaboration Blog &middot; articles in the "misc" category</title>
<!--        <link rel="shortcut icon" href="http://osc.centerforopenscience.org/favicon.ico" /> -->
		<link rel="shortcut icon" href="http://mcohn.net/rp/favicon.ico" />
<link href="http://osc.centerforopenscience.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Open Science Collaboration Blog Atom Feed" />

        <link rel="stylesheet" href="http://osc.centerforopenscience.org/theme/css/screen.css" type="text/css" />
        <link rel="stylesheet" href="http://osc.centerforopenscience.org/theme/css/pygments.css" type="text/css" />


    </head>
    <body>
<div id="header">
            <ul id="nav">
                <li class="ephemeral selected"><a href="http://osc.centerforopenscience.org/category/misc.html">misc</a></li>
                <li><a href="http://osc.centerforopenscience.org">Home</a></li>
<li><a href="http://osc.centerforopenscience.org/pages/about.html">About</a></li>
<li><a href="http://osc.centerforopenscience.org/pages/authors.html">Authors</a></li>
<li><a href="http://osc.centerforopenscience.org/pages/policy.html">Policy</a></li>
<li><a href="http://osc.centerforopenscience.org/archives.html">Archives</a></li>
            </ul>
            <div class="header_box">
                <h1><a href="http://osc.centerforopenscience.org"><img src="http://osc.centerforopenscience.org/images/osc-redblack.png" width="160px" style="margin-top:-60px;" /></a></h1>
            </div>
        </div>
        <div id="wrapper">
            <div id="content">
                <h4 class="date">Oct 10,  2013</h4>
                <div class="post">
<h2 class="title">
                        <a href="http://osc.centerforopenscience.org/2013/10/10/opportunities-for-collaborative-research/" rel="bookmark" title="Permanent Link to &quot;Opportunities for Collaborative Research&quot;">Opportunities for Collaborative Research</a>
                    </h2>

                    by <a href="http://osc.centerforopenscience.org/author/jon-grahe-pacific-lutheran-university.html" rel="author">Jon Grahe, Pacific Lutheran University</a>

   			   <p><img src="/images/jongrahe-headshot.jpg" alt="Photo of Jon Grahe" align="left" style="padding-right: 20px;" width="150px" /></p>
<p>As a research methods instructor, I encourage my students to conduct “authentic” research projects. For now, consider authentic undergraduate research experiences as student projects at any level where the findings might result in a conference presentation or a publishable paper. This included getting IRB approval and attempts to present our findings at regional conferences, maybe including a journal submission. Eventually, I participated in opportunities for my students to contribute to big science by joining in two crowd-sourcing projects organized by Alan Reifman. The first was published in Teaching of Psychology (School Spirit Study Group, 2004) as an example for others to follow. The data included samples from 22 research methods classes who measured indices representative of the group name. Classes evaluated the data from their own school and the researchers collapsed the data to look at generalization across institutions. The second collaborative project included surveys collected by students in 10 research methods classes. The topic was primarily focused on emerging adulthood and political attitudes, but included many other psychological constructs. Later, I note the current opportunities for Emerging Adulthood theorists to use these data for a special issue of the journal, Emerging Adulthood. These two projects notwithstanding, there have been few open calls for instructors to participate in big science. Instructors who want to include authentic research experiences do so by completing all their own legwork as characterized by Frank and Saxe (2012) or as displayed by many of the poster presentations that you see at Regional Conferences.</p>
<p>However, that state of affairs has changed. Though instructors are likely to continue engaging in authentic research in their classrooms, they don’t have to develop the projects on their own anymore. I am very excited about the recent opportunities that allow students to contribute to “big science” by acting as crowd-sourcing experimenters. In full disclosure, I acknowledge my direct involvement in developing three of the following projects. However, I will save you a description of my own pilot test called the Collective Undergraduate Research Project (Grahe, 2010). Instead, I will briefly review recent “open invitation projects”, those where any qualified researcher can contribute. The first to emerge (Psych File Drawer, Reproducibility Project) were focused on PhD level researchers. However, since August 2012 there have been three research projects that specifically invite students to help generate data either as experimenters or as coders. More are likely to emerge soon as theorists grasp the idea that others can help them collect data.</p>
<p>This is a great time to be a research psychologist. These projects provide real opportunities for students or other researchers at any expertise level to get involved in not only authentic, but transformative research opportunities. The Council of Undergraduate Research recently published an edited volume (Karukstis &amp; Hensel, 2010) dedicated to fostering transformative research for undergraduates. According to Wikipedia, “Transformative research is a term that became increasingly common within the science policy community in the 2000s for research that shifts or breaks existing scientific paradigms.” I consider open invitation projects transformative because they change the way that we view minimally acceptable standards for research. Each one is intended to change the basic premise of collaboration by bridging not only institutions, but also the chasm of acquaintance. Any qualified researcher can participate in data collection and authorship. Now, when I introduce research opportunities to my students, the ideas are grand. Here are research projects with grand ideas that invite contributions.</p>
<p><em>Many Labs Project</em> - The Many Labs Team’s original invitation to contributors, sent out in <a href="https://groups.google.com/forum/#!topic/openscienceframework/CwwRtaUMl4I">February 2013</a> asked contributors to join their “wide-scale replication project {that was} conditionally accepted for publication in the special issue of Social Psychology.” They made a follow-up invitation in July reminding us of their Oct. 1st, 2013 deadline for data collection. This deadline limits future contributors, but it is a great example of a crowd-sourcing project. Their goal is to replicate 12 effects using the <a href="https://implicit.harvard.edu">Project Implicit</a> infrastructure. As is typical of these projects, contributors meeting a minimum goal (N &gt; 80 cases in this instance) will be listed as coauthors in future publications. As they stated in their July post, “The project and accepted proposal has been registered on the Open Science Framework and can be found at this link: <a href="http://www.openscienceframework.org/project/WX7Ck/">http://www.openscienceframework.org/project/WX7Ck/</a>.” Richard Klein (project coordinator) reported that their project includes 18 different researchers at 15 distinct labs, with a plan for 38 labs contributing data before the deadline. This project is nearing the completion deadline and so new contributions are limited, but the project represents an important exemplar of potential projects.</p>
<p><em>Reproducibility Project</em> – As stated on their <a href="https://openscienceframework.org/project/EZcUj/wiki/new-contributors:replicate">invitation to new contributors</a> on the Open Science Framework page, "Our primary goal is to conduct high quality replications of studies from three 2008 psychology journals and then compare our results to the original studies." As of right now, Johanna Cohoon from the Center for Open Science states, “We have 136 replication authors who come from 59 different institutions, with an additional 19 acknowledged replication researchers (155 replication researchers total). We also have an additional 40 researchers who are not involved in a replication that have earned authorship through coding/vetting 10 or more articles.” In short, this is a large collaboration and is welcoming more committed researchers. Though this project needs advanced researchers, it is possible for faculty to work closely with students who might wish to contribute.</p>
<p><em>PsychFileDrawer Project</em> – This is less a collaborative effort between researchers than a compendium of replications, <a href="http://www.psychfiledrawer.org/about.php">as stated</a> by the project organizers: “PsychFileDrawer.org is a tool designed to address the File Drawer Problem as it pertains to psychological research: the distortion in the scientific literature that results from the failure to publish non-replications." It is collaborative in the sense that they host a “top 20” list of studies that the viewers want to see replicated. However, any researcher with a replication is invited to contribute the data. Further, although this was not initially targeted toward students, there is a new feature that allows contributors to identify a sample as a class project and <a href="http://www.psychfiledrawer.org/faq.php">the FAQ page</a> asks instructors to comment on, “…the level and type of instructor supervision, and instructor’s degree of confidence in the fidelity with which the experimental protocol was implemented.” </p>
<p><em>Emerging Adulthood, Political Decisions, and More (2004) project</em> – Alan Reifman is an early proponent of collaborative undergraduate research projects. After successfully guiding the School Spirit Study Group, he called again to research methods instructors to collectively conduct a survey that included two emerging adulthood scales, some political attitudes and intentions, and other scales that contributors wanted to add to the paper and pencil survey. By the time the survey was finalized, it was over 10 pages long and included hundreds of individual items measuring dozens of distinct psychological constructs on 12 scales. In retrospect, the survey was too long and the invitation to add on measures might have caused of the attrition of committed contributors that occurred. However, the final sample included over 1300 cases from 11 distinct institutions across the US. A list of contributors and initial findings can be found at Alan Reifman’s <a href="http://courses.ttu.edu/hdfs3390-reifman/fall04project.htm">Emerging Adulthood Page</a>. This project suffered from the amorphous structure of the collaboration. In short, no one instructor was interested in all the constructs. To resolve this situation where wonderfully rich data sit unanalyzed, the contributors are inviting emerging adulthood theorists to analyze the data and submit their work for a special issue of Emerging Adulthood. Details for how to request the data are available on <a href="https://openscienceframework.org/project/yjdaf/">the project’s OSF page</a>. The deadline for a submission is July, 2014.</p>
<p><em>International Situations Project (ISP)</em> – David Funder and Esther Guillaume-Hanes from the University of California—Riverside have organized a coalition of international researchers (19 and counting) to complete an internet protocol. As they describe on their about page, “Participants will describe situations by writing a brief description of the situation they experienced the previous day at 7 pm. They will identify situational characteristics uing the Riverside Situation Q-sort (RSQ) which includes 89 items that participants place into one of nine categories ranging from not at all characteristic to very characteristics. They then identify the behaviors they displayed using the Riverside Behavioral Q-Sort (RBQ) which includes 68 items using <a href="http://www.internationalsituationsproject.com/about">the same sorting procedure</a>. The UC-Riverside researchers are taking primary responsibility for writing research reports.  They have papers in print and others in preparation where all contributors who provide more than 80 cases are listed as authors. In Fall 2012, Psi Chi and Psi Beta encouraged their members to replicate the ISP in the US to create a series of local samples yielding 11 samples with 5 more committed contributors (Grahe, Guillaume-Hanes, &amp; Rudmann, 2014). Currently, contributors are invited to complete either this project or their subsequent Personality project which includes completing this protocol, then completing the California Adult Q-Sort two weeks later. Interested researchers should contact Esther Guillaume directly at eguil002@ucr.edu.</p>
<p><em>Collaborative Replications and Education Project (CREP)</em> – <a href="https://openscienceframework.org/project/WFC6u/">This project</a> has recently started inviting contributions and is explicitly designed for undergraduates. Instructors who guide student research projects are encouraged to share the available studies list with their students. Hans IJzerman and Mark Brandt reviewed the top three cited empirical articles in the top journals in nine sub disciplines and rated them for feasibility to be completed by undergraduates selecting nine studies that were the most feasible. The project provides small ($200-$500) CREP research awards for completed projects (sponsored by Psi Chi and the Center for Open Science). Contributors will be encouraged/supported in writing and submitting reports for publication by the project coordinators. Anyone interested in participating should contact Jon Grahe (graheje@plu.edu).</p>
<p><em>Archival Project</em> – This Center for Open Science <a href="http://archivalproject.org/">project</a> is also specifically designed as a crowd-sourcing opportunity for students. When it completes the beta-testing phase, the Archival Project will be publicly advertised. Unlike all the projects reviewed thus far, this project asks contributors to serve as coders rather than act as experimenters. It is a companion project to the OSC Reproducibility Project in that the target articles are from the same three Journals from the first three months of 2008. This project has a low bar for entry as training can take little time (particularly with the now available online tutorial) and coders can code as few as a single article and still make a real contribution. However, this project also has a system of honors as they state on their <a href="http://archivalproject.org/pages/getting_involved">“getting involved” page</a>:  “Contributors who provide five or more accurate codings will be listed as part of the collective authorship.”  This project was designed with the expectation that instructors will find the opportunity pedagogically useful and that they will employ it as a course exercise. Alternatively, students in organized clubs (such as Psi Chi) are invited to participate to increase their own methodological competence while simultaneously accumulating evidence of their contributions to an authentic research project. Finally, graduate students are invited to participate without faculty supervision. Interested parties should contact Johanna Cohoon (johannacohoon@gmail.com) for more information.</p>
<p><em>Future Opportunities</em> – While this is intended to be an exhaustive list of open invitation projects, the field is not static and this list is likely to grow. What is exciting is that we now have ample opportunities to participate in “big science” with relatively small contributions. When developed with care, these projects follow Grahe et al. (2012)’s recommendation to take advantage of the magnitude of research being conducted each year by psychology students. The bar for entry varies in these projects from relatively intensive (e.g. Reproducibility Project, CREP) to relatively easy (e.g. Archival Project, ISP), providing opportunities for individuals with varying resources, from graduate students and PhD level researchers capable of completing high quality replications to students and instructors who seek opportunities in the classroom. Beyond the basic opportunity to participate in transformative research, these projects provide exemplars for how future collaborative projects should be designed and managed.</p>
<p>This is surely an incomplete list of current or potential examples of crowd-sourcing research. Please share other examples as comments below. Further consider pointing out strengths, weaknesses, opportunities or threats that could emerge from collaborative research. Finally, any public statements about intentions to participate in this type of open science initiative are welcome. </p>
<p><strong>References</strong></p>
<p>Frank, M. C., &amp; Saxe, R. (2012). Teaching replication. <em>Perspectives On Psychological Science</em>,   7(6), 600-604. doi:10.1177/1745691612460686</p>
<p>Grahe. J. E., Gullaume-Hanes, E., &amp; Rudmann, J. (2014). Students collaborate to advance science: The International Situations Project. <em>Council for Undergraduate Research Quarterly</em></p>
<p>Grahe, J. E., Reifman, A., Hermann, A. D., Walker, M., Oleson, K. C., Nario-Redmond, M., &amp; Wiebe, R. P. (2012). Harnessing the undiscovered resource of student research projects. <em>Perspectives On Psychological Science</em>, 7(6), 605-607. doi:10.1177/1745691612459057</p>
<p>Karukstis, K. K., &amp; Hensel, N. (2010) Transformative research at predominately undergraduate institutions.” Council of Undergraduate Research. Washington DC., USA.</p>
                    <div class="clear"></div>
                    <div class="info">
<a href="http://osc.centerforopenscience.org/2013/10/10/opportunities-for-collaborative-research/#disqus_thread" data-disqus-identifier="2013/10/10/opportunities-for-collaborative-research/" style="text-decoration:underline; color: black">Discuss this post</a> | <a href="http://osc.centerforopenscience.org/2013/10/10/opportunities-for-collaborative-research/">Posted at 12:00 am</a>&nbsp;&middot;&nbsp;<a href="http://osc.centerforopenscience.org/category/misc.html" rel="tag">misc</a>
                    </div>
                    <div class="clear"></div>
                </div>

                <h4 class="date">Oct  4,  2013</h4>
                <div class="post">
<h2 class="title">
                        <a href="http://osc.centerforopenscience.org/2013/10/04/a-publishing-sting-but-what-was-stung/" rel="bookmark" title="Permanent Link to &quot;A publishing sting, but what was stung?&quot;">A publishing sting, but what was stung?</a>
                    </h2>

                    by <a href="http://osc.centerforopenscience.org/author/ase-innes-ker.html" rel="author">Åse Innes-Ker</a>

   			   <p>Before Open Science there was Open Access (OA) — a movement driven by the
desire to make published research publicly accessible (after all, the public
usually had paid for it), rather than hidden behind paywalls.</p>
<p>Open Access is, by now, its very own strong movement — follow for example <a href="http://bjoern.brembs.net/">Björn
Brembs</a> if you want to know what is happening there — and 
there are now nice Open Access journals, like <a href="http://www.plos.org/">PLOS</a> and
<a href="http://www.frontiersin.org/">Frontiers</a>, which are
peer-reviewed and reputable. Some of these journals charge an article
processing fee for OA articles, but in many cases funders have introduced or
are developing provisions to cover these costs. (In fact, the big private
funder in Sweden INSISTS on it.)</p>
<p>But, as always, situations where there is money involved and targets who are
desperate (please please please publish my baby so I won’t perish) breed mimics
and cuckoos and charlatans, ready to game the new playing field to their
advantage.  This is probably just a feature of the human condition (see
Triver’s “<a href="http://www.amazon.com/The-Folly-Fools-Deceit-Self-Deception/dp/B008PGKA56">Folly of Fools</a>”).</p>
<p>There are lists of potentially predatory Open Access journals — I have linked
some in on my private blog (Åse Fixes Science)
<a href="http://asefixesscience.wordpress.com/2013/04/14/open-access-watch-out-list/">here</a>
and
<a href="http://asefixesscience.wordpress.com/2013/05/12/more-on-predatory-open-access/">here</a>.
Reputation counts.  Buyers beware!</p>
<p>Demonstrating the challenges of this new marketplace, John Bohannon published
in Science (a decidedly not Open Access journal) a sting operation in which he
spoofed Open Access journals to test their peer-review system. The papers were
machine generated nonsense — one may recall the <a href="http://en.wikipedia.org/wiki/Sokal_affair">Sokal Hoax</a> from the previous
Science Wars.  One may also recall the classic Ceci paper from 1982, which made
the rounds again earlier this year (and I blogged about that one too - <a href="http://asehelene.wordpress.com/2013/05/31/music-social-proof-appeal-and-peer-review/">on my
other blog</a>).</p>
<p>Crucially, all of Bohannon’s papers contained fatal flaws that a decent
peer-reviewer should catch. The big news? Lots of them did not (though PLOS
did). Here’s the <a href="http://www.sciencemag.org/content/342/6154/60">Science</a> article with
its <a href="http://comments.sciencemag.org/content/10.1126/science.342.6154.60">commentary stream</a>,
and a commentary from <a href="http://retractionwatch.wordpress.com/2013/10/03/science-reporter-spoofs-hundreds-of-journals-with-a-fake-paper/">Retraction Watch</a>).</p>
<p>This is, of course, interesting — and it is generating buzz.  But, it is also
generating some negative reaction. For one, Bohannon did not include the
regular non-OA journals in his test, so the experiment lacks a control group,
which means we can make no comparison and draw no firm inferences from the
data. The reason he states (it is quoted on the Retraction Watch site) is the
very long turnaround times for regular journals, which can be months, even a
year (or longer, as I’ve heard). I kinda buy it, but this is really what is
angering the Open Access crowd, who sees this letter as an attempt to
implicate Open Access itself as the source of the problem. And, apart from
Bohannon not including regular journals in his test, Science published what he
wrote without peer reviewing it.</p>
<p>My initial take? I think it is important to test these things — to uncover the
flaws in the system, and also to uncover the cuckoos and the mimics and the
gamers. Of course, the problems in peer review are not solely on the shoulders
of Open Access — Diederik Stapel, and other frauds, published almost
exclusively in paywalled journals (including Science).  The status of peer
review warrants its own scrutiny.</p>
<p>But, I think the Open Access advocates have a really important point to
make.  As noted on Retraction Watch, Bohannon's study didn't include
non-OA journals, so it's unclear whether the peer-review problems he
identified in OA journals are unique to their OA status.</p>
<p>I’ll end by linking in some of the commentary that I have seen so far — and, of
course, we’re happy to hear your comments.</p>
<ul>
<li>The Guardian: <a href="http://www.theguardian.com/higher-education-network/2013/oct/04/open-access-journals-fake-paper">Hundreds of Open Access journals accept fake science paper</a></li>
<li>Peter Suber: <a href="https://plus.google.com/109377556796183035206/posts/CRHeCAtQqGq">New “Sting” of Weak Open-Access Journals</a></li>
<li>Curt Rice: <a href="http://curt-rice.com/2013/10/04/what-science-and-the-gonzo-scientist-got-wrong-open-access-will-make-research-better/">What Science — and the Gonzo Scientist — got wrong</a></li>
<li>The conversation: <a href="http://theconversation.com/flawed-sting-operation-singles-out-open-access-journals-18846">Flawed sting operation</a></li>
<li>The comics Grid: <a href="http://blog.comicsgrid.com/2013/10/whos-afraid-open-access/">Who's afraid of Open Access</a></li>
<li>Michael Eisen: <a href="http://www.michaeleisen.org/blog/?p=1439">I confess, I wrote the Arsenic DNA paper to expose flaws in peer-review at subscription based journals</a></li>
<li><a href="https://twitter.com/search?had_popular=true&amp;q=JournalSting">#JournalSting</a> and <a href="https://twitter.com/search?q=%23openaccess&amp;src=hash">#openaccess</a> on Twitter</li>
<li>Sauropod Vertebra Picture of the week: <a href="http://svpow.com/2013/10/03/john-bohannons-peer-review-sting-against-science/">John Bohannon’s peer-review sting against Science</a>. (The last one is also collecting other links commenting on this paper - good resource).</li>
</ul>
                    <div class="clear"></div>
                    <div class="info">
<a href="http://osc.centerforopenscience.org/2013/10/04/a-publishing-sting-but-what-was-stung/#disqus_thread" data-disqus-identifier="2013/10/04/a-publishing-sting-but-what-was-stung/" style="text-decoration:underline; color: black">Discuss this post</a> | <a href="http://osc.centerforopenscience.org/2013/10/04/a-publishing-sting-but-what-was-stung/">Posted at  2:45 pm</a>&nbsp;&middot;&nbsp;<a href="http://osc.centerforopenscience.org/category/misc.html" rel="tag">misc</a>
                    </div>
                    <div class="clear"></div>
                </div>

                <h4 class="date">Oct  2,  2013</h4>
                <div class="post">
<h2 class="title">
                        <a href="http://osc.centerforopenscience.org/2013/10/02/smoking-on-an-airplane/" rel="bookmark" title="Permanent Link to &quot;Smoking on an Airplane&quot;">Smoking on an Airplane</a>
                    </h2>

                    by <a href="http://osc.centerforopenscience.org/author/denny-borsboom.html" rel="author">Denny Borsboom</a>

   			   <p><img src="/images/DennyPortrait-cropped.png" alt="Photo of Denny
Boorsboom" align="left" style="padding-right: 20px;" width="200px" /></p>
<p>People used to smoke on airplanes. It's hard to imagine, but it's true. In less
than twenty years, smoking on airplanes has grown so unacceptable that it has
become difficult to see how people ever condoned it in the first place.
Psychological scientists used to refuse to share their data. It's not so hard to
imagine, and it's still partly true. However, my guess is that a few years from
now, data-secrecy will be as unimaginable as smoking on an airplane is today.
We've already come a long way. When in 2005 Jelte Wicherts, Dylan Molenaar,
Judith Kats, and I asked 141 psychological scientists to send us their raw data
to verify their analyses, many of them told us to get lost - even though, at
the time of publishing the research, they had signed an agreement to share
their data upon request. "I don't have time for this," one famous psychologist
said bluntly, as if living up to a written agreement is a hobby rather than a
moral responsibility. Many psychologists responded in the same way. If they
responded at all, that is.</p>
<p>Like Diederik Stapel.</p>
<p>I remember that Judith Kats, the student in our group who prepared the emails
asking researchers to make data available, stood in my office. She explained to
me how researchers had responded to our emails. Although many researchers
had refused to share data, some of our Dutch colleagues had done so in an
extremely colloquial, if not downright condescending way. Judith asked me how
she should respond. Should she once again inform our colleagues that they had
signed an APA agreement, and that they were in violation of a moral code?</p>
<p>I said no.</p>
<p>It's one of the very few things in my scientific career that I regret. Had we
pushed our colleagues to the limit, perhaps we would have been able to identify
Stapel's criminal practices years earlier. As his autobiography shows, Stapel
counterfeited his data in an unbelievably clumsy way, and I am convinced that
we would have easily identified his data as fake.
I had many reasons for saying no, which seemed legitimate at the time, but in
hindsight I think my behavior was a sign of adaptation to a defective research
culture. I had simply grown accustomed to the fact that, when I entered an
elevator, conversations regarding statistical analyses would fall silent. I took
it as a fact of life that, after we methodologists had explained students how to
analyze data in a responsible way, some of our colleagues would take it upon
themselves to show students how scientific data analysis really worked (today,
these practices are known as p-hacking). We all lived in a scientific version of
The Matrix, in which the reality of research was hidden from all - except those
who had the doubtful honor of being initiated. There was the science that people
reported and there was the science that people did.</p>
<p>In Groningen University, where Stapel used to work, he was known as The Lord
of the Data, because he never let anyone near his SPSS files. He pulled results
out of thin air, throwing them around as presents to his co-workers, and when
anybody asked him to show the underlying data files, he simply didn't respond.
Very few people saw this as problematic, because, hey, these were his data, and
why should Stapel share his data with outsiders?</p>
<p>That was the moral order of scientific psychology. Data are private property.
Nosy colleagues asking for data? Just chase them away, like you chase coyotes
from your farm. That is why researchers had no problem whatsoever denying
access to their data, and that is why several people saw the data-sharing request
itself as unethical. "Why don't you trust us?," I recall one researcher saying in a
suspicious tone of voice.</p>
<p>It is unbelievable how quickly things have changed.</p>
<p>In the wake of the Stapel case, the community of psychological scientists
committed to openness, data-sharing, and methodological transparency quickly
reached a critical mass. The <a href="https://openscienceframework.org">Open Science Framework</a> allows researchers to
archive all of their research materials, including stimuli, analysis code, and
data, to make them public by simply pressing a button. The new <a href="http://openpsychologydata.metajnl.com">Journal of Open
Psychology Data</a> offers an outlet
specifically designed to publish datasets, thereby giving these the status of a
publication. <a href="http://psychdisclosure.org">PsychDisclosure.org</a> asks researchers to document decisions
regarding, e.g., sample size determination and variable selection, that were
left unmentioned in publications; most researchers provide this information
without hesitation - some actually do so voluntarily. The journal Psychological
Science will likely implement requirements for this type information in the
submission process. Data-archiving possibilities are growing like crazy. Major
funding institutes require data-archiving or are preparing regulations that do.
In the <a href="https://openscienceframework.org/project/EZcUj/wiki/home">Reproducibility Project</a>, hundreds of studies are being replicated in a
concerted effort. As a major symbol of these developments, we now have the
<a href="http://centerforopenscience.org">Center for Open Science</a>, which facilitates the massive grassroots effort to
open up the scientific regime in psychology.</p>
<p>If you had told me that any of this would happen back in 2005, I would have
laughed you away, just as I would have laughed you away in 1990, had you told
me that the future would involve such bizarre elements as smoke-free airplanes.</p>
<p>The moral order of research in psychology has changed. It has changed for the
better, and I hope it has changed for good.</p>
                    <div class="clear"></div>
                    <div class="info">
<a href="http://osc.centerforopenscience.org/2013/10/02/smoking-on-an-airplane/#disqus_thread" data-disqus-identifier="2013/10/02/smoking-on-an-airplane/" style="text-decoration:underline; color: black">Discuss this post</a> | <a href="http://osc.centerforopenscience.org/2013/10/02/smoking-on-an-airplane/">Posted at 10:30 am</a>&nbsp;&middot;&nbsp;<a href="http://osc.centerforopenscience.org/category/misc.html" rel="tag">misc</a>
                    </div>
                    <div class="clear"></div>
                </div>

                <div class="post">
<h2 class="title">
                        <a href="http://osc.centerforopenscience.org/2013/10/02/welcome/" rel="bookmark" title="Permanent Link to &quot;Welcome!&quot;">Welcome!</a>
                    </h2>

                    by <a href="http://osc.centerforopenscience.org/author/osc.html" rel="author">OSC</a>

   			   <p>Welcome to the blog of the Open Science Collaboration! We are a loose network of researchers, professionals, citizen scientists, and others with an interest in open science, metascience, and good scientific practices.  We’ll be writing about:</p>
<ul>
<li>Open science topics like reproducibility, transparency in methods and analyses, and changing editorial and publication practices</li>
<li>Updates on open science initiatives like the <a href="https://openscienceframework.org/reproducibility/‎">Reproducibility Project</a> and opportunities to get involved in new projects like the <a href="http://archivalproject.org/">Archival Project</a></li>
<li>Interviews and opinions from researchers, developers, publishers, and citizen scientists working to make science more transparent, rigorous, or reproducible. </li>
</ul>
<p>We hope that the blog will stimulate open discussion and help improve the way science is done!</p>
<p>If you'd like to suggest a topic for a post, propose a guest post or column, or get involved with moderation, promotion, or technical development, we would love to hear from you! Email us at <a href="mailto:oscbloggers@gmail.com">oscbloggers@gmail.com</a> or tweet @OSCbloggers.</p>
<p>The OSC is an open collaboration - anyone is welcome to join, contribute to discussions, or develop a project. The OSC blog is supported by the <a href="http://centerforopenscience.org">Center for Open Science</a>, a non-profit organization dedicated to increasing openness, integrity and reproducibility of scientific research.  </p>
                    <div class="clear"></div>
                    <div class="info">
<a href="http://osc.centerforopenscience.org/2013/10/02/welcome/#disqus_thread" data-disqus-identifier="2013/10/02/welcome/" style="text-decoration:underline; color: black">Discuss this post</a> | <a href="http://osc.centerforopenscience.org/2013/10/02/welcome/">Posted at 10:15 am</a>&nbsp;&middot;&nbsp;<a href="http://osc.centerforopenscience.org/category/misc.html" rel="tag">misc</a>
                    </div>
                    <div class="clear"></div>
                </div>

                <div class="clear"></div>
                <div class="pages">
                    <a href="http://osc.centerforopenscience.org/category/misc4.html" class="prev_page">&larr;&nbsp;Previous</a>
                    <span>Page 5 of 5</span>
                </div>

                <div class="clear"></div>
                <div id="footer">
                    <p>
                    Mockingbird theme by <a href="http://nevanscott.com/">Nevan Scott</a>
                    &middot;
                    <a class="atom" href="http://osc.centerforopenscience.org/feeds/all.atom.xml">Feed</a>
                </div>
            </div>
            <div class="clear"></div>
        </div>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44517264-1', 'centerforopenscience.org');
  ga('send', 'pageview');

</script>
<script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'opensciencecollaboration'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function () {
var s = document.createElement('script'); s.async = true;
s.type = 'text/javascript';
s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>


    </body>
</html>