<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
        <title>Open Science Collaboration Blog &middot; What we talk about when we talk about replication</title>
<!--        <link rel="shortcut icon" href="http://osc.centerforopenscience.org/favicon.ico" /> -->
		<link rel="shortcut icon" href="http://mcohn.net/rp/favicon.ico" />
<link href="http://osc.centerforopenscience.org/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Open Science Collaboration Blog Atom Feed" />

        <link rel="stylesheet" href="http://osc.centerforopenscience.org/theme/css/screen.css" type="text/css" />
        <link rel="stylesheet" href="http://osc.centerforopenscience.org/theme/css/pygments.css" type="text/css" />


    </head>
    <body>
<div id="header">
            <ul id="nav">
                <li><a href="http://osc.centerforopenscience.org">Home</a></li>
<li><a href="http://osc.centerforopenscience.org/pages/about.html">About</a></li>
<li><a href="http://osc.centerforopenscience.org/pages/authors.html">Authors</a></li>
<li><a href="http://osc.centerforopenscience.org/pages/policy.html">Policy</a></li>
<li><a href="http://osc.centerforopenscience.org/archives.html">Archives</a></li>
            </ul>
            <div class="header_box">
                <h1><a href="http://osc.centerforopenscience.org"><img src="http://osc.centerforopenscience.org/images/osc-redblack.png" width="160px" style="margin-top:-60px;" /></a></h1>
            </div>
        </div>
        <div id="wrapper">
            <div id="content">
                <h4 class="date">Jul 30,  2014</h4>
                <div class="post">
<h2 class="title">
                        <a href="http://osc.centerforopenscience.org/2014/07/30/talk-about-replication/" rel="bookmark" title="Permanent Link to &quot;What we talk about when we talk about replication&quot;">What we talk about when we talk about replication</a>
                    </h2>

                    by <a href="http://osc.centerforopenscience.org/author/shauna-gordon-mckeon.html" rel="author">Shauna Gordon-McKeon</a>

   			   <p>If I said, “Researcher A replicated researcher B’s work”, what would you take me to mean?  </p>
<p>There are many possible interpretations. I could mean that A had repeated precisely the methods of researcher B, and obtained similar results.  Or I could be saying that A had repeated precisely the methods of researcher B, and obtained very different results.  I could be saying that A had repeated only those methods which were theorized to influence the results.  I could mean that A had devised new methods which were meant to explore the same phenomenon.  Or I could mean that researcher B had copied everything down to the last detail.  </p>
<p>We do have terms for these different interpretations.  A replication of precise methods is a direct replication, while a replication which uses new methods but gets at the same phenomenon is a conceptual replication.  Once a replication has been completed, you can look at the results and call it a “successful replication” if the results are the same, and a “failed replication” if the results are different.  </p>
<p>Unfortunately, these terms are not always used, and the result is that recent debates over replication have become not only heated, but confused.  </p>
<p>Take, for instance, nobel laureate Daniel Kahneman’s open letter to the scientific community, <a href="http://www.scribd.com/doc/225285909/Kahneman-Commentary">A New Etiquette for Replication</a>.  He writes:  </p>
<blockquote>
<p>“Even rumors of a failed replication cause immediate reputational damage by raising a suspicion of negligence (if not worse). The hypothesis that the failure is due to a flawed replication comes less readily to mind – except for authors and their supporters, who often feel wronged.” </p>
</blockquote>
<p>Here he uses the common phrasing, “failed replication”, to indicate a replication where different results were obtained.  The cause of those different results is unknown, and he suggests that one option is that the methods used in the direct replication were not correct, which he calls a “flawed replication”.  What, then, is the term for a replication where the methods were correct but the results were still not found?</p>
<p>Further on in his letter, Kahneman adds:</p>
<p>“In the myth of perfect science, the method section of a research report always includes enough detail to permit a direct replication. Unfortunately, this seemingly reasonable demand is rarely satisfied in psychology, because behavior is easily affected by seemingly irrelevant factors.”  </p>
<p>We take “direct replication” to mean copying the original researcher’s methods.  As Kahneman points out, perfect copying is impossible.  When a factor that once seemed irrelevant may have influenced the results, is that a “flawed replication”, or simply no longer a “direct replication”?  How can we distinguish between replications which copy as much of the methods as possible, and those which copy only those elements of the methods which the original author hypothesizes should influence the result?</p>
<p>This terminology is not only imprecise, it differs from what others use.  In their <a href="http://www.psycontent.com/content/311q281518161139/fulltext.html">Registered Reports: A Method to Increase the Credibility of Published Results</a>, Brian Nosek and Daniel Lakens write:</p>
<p>“There is no such thing as an exact replication. Any replication will differ in innumerable ways from the original. A direct replication is the attempt to duplicate the conditions and procedure that existing theory and evidence anticipate as necessary for obtaining the effect (Open Science Collaboration, 2012, 2013; Schmidt, 2009). Successful replication bolsters evidence that all of the sample, setting, and procedural differences presumed to be irrelevant are, in fact, irrelevant.”</p>
<p>This statement contains an admirably clear definition of “direct replication”, which the authors use here to mean a replication copying only those elements of the methods considered relevant.  This is distinct from Kahneman’s usage of the term “direct replication”.  Kahneman, instead, may be conflating “direct replication” with “literal replication”, a much less common term meaning “the precise duplication of the specific design and results of a previous study” (<a href="http://www.psychwiki.com/wiki/What_is_a_literal_replication%3F">Heiman, 2002</a>).</p>
<p>Nosek and Lakens also use the term “successful replication” in a way which implies that not only were the results replicated, the methods were as well, as they take the replication’s success to be a commentary on the methods.  However, even “successful replications” may not successfully replicate methods, as pointed out by <a href="http://www.spspblog.org/simone-schnall-on-her-experience-with-a-registered-replication-project/">Simone Schnall</a> in her critique of the special issue edited by Nosek and Lakens:</p>
<p>Various errors in several of the replications (e.g., in the <a href="http://www.psycontent.com/content/n657m04571w51j70/?p=5709f7ef6aaf4a4ea65b5433c116abbe&amp;pi=1">“Many Labs”</a> paper) became only apparent once original authors were allowed to give feedback. Errors were uncovered even for successfully replicated findings. </p>
<p>Whether or not there were methodological errors in these particular cases, the possibility of such errors even when results are replicated remains a possibility, one which is elided by the terminology of “successful replication”.  This is not merely a point of semantics, as successful replications may be checked less carefully for methodological errors than “failed replications”.</p>
<p>There are many other examples of researchers using replication terminology in ways that are not maximally clear.  So far I have only quoted from social psychologist.  When we attempt to speak across disciplines our terminology faces even more problems.</p>
<p>As such, I propose:</p>
<p>1)  That we resurrect the term “literal replication”, meaning “the precise duplication of the specific design of a previous study” rather than overload the term “direct replication”.  Direct replication can then mean only the duplication of those methods deemed to be relevant.  Of course, a perfect literal replication is impossible, but using this terminology implies that duplication of as much of the previous study as possible is the goal.</p>
<p>2)  That we retire the phrases “failed replication” and “successful replication”, which do not distinguish between procedure and results.  In their place, we can use “replication with different results” and “flawed replication” for the former, and “replication with similar results” and “sound replication” for the latter.</p>
<p>Thus, a replication attempt where the goal was to precisely duplicate materials and where this was successfully done, but different results were found, would be a sound literal replication with different results.  An attempt only to duplicate elements of the design hypothesized to be relevant, leading to some methodological questions, yet where similar results were found, would be a flawed direct replication with similar results.</p>
<p>These terms may seem unnecessarily wordy, and indeed may not always be needed, but I encourage everyone to use them when precision is important, for instance in published articles or in debates with those who disagree with you.  I know that from now on, when I hear someone use the bare term “replication”, I will ask, “What kind?”</p>
<p><em>Thanks to JP de Ruiter, Etienne LeBel, and Sheila Miguez for their feedback on this post.</em></p>
                    <div class="clear"></div>
                    <div class="info">
<a href="http://osc.centerforopenscience.org/2014/07/30/talk-about-replication/#disqus_thread" data-disqus-identifier="2014/07/30/talk-about-replication/" style="text-decoration:underline; color: black">Discuss this post</a> | <a href="http://osc.centerforopenscience.org/2014/07/30/talk-about-replication/">Posted at 12:00 pm</a>&nbsp;&middot;&nbsp;<a href="http://osc.centerforopenscience.org/category/misc.html" rel="tag">misc</a>
                    </div>
                    <div class="clear"></div>
                </div>




                <div class="clear"></div>
                <div id="footer">
                    <p>
                    Mockingbird theme by <a href="http://nevanscott.com/">Nevan Scott</a>
                    &middot;
                    <a class="atom" href="http://osc.centerforopenscience.org/feeds/all.atom.xml">Feed</a>
                </div>
            </div>
            <div class="clear"></div>
        </div>
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-44517264-1', 'centerforopenscience.org');
  ga('send', 'pageview');

</script>
<script type="text/javascript">
/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
var disqus_shortname = 'opensciencecollaboration'; // required: replace example with your forum shortname

/* * * DON'T EDIT BELOW THIS LINE * * */
(function () {
var s = document.createElement('script'); s.async = true;
s.type = 'text/javascript';
s.src = 'http://' + disqus_shortname + '.disqus.com/count.js';
(document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>


    </body>
</html>